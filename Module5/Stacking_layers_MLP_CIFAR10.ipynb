{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n9El1-v1N0N"
      },
      "source": [
        "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQUpDURe1N0P"
      },
      "source": [
        "# [Module 5](https://dataflowr.github.io/website/modules/5-stacking-layers/): overfitting a MLP on CIFAR10\n",
        "\n",
        "Training loop over CIFAR10 (40,000 train images, 10,000 test images). What happens if you\n",
        "- switch the training to a GPU? Is it faster?\n",
        "- Remove the `ReLU()`?\n",
        "- Increase the learning rate?\n",
        "- Stack more layers?\n",
        "- Perform more epochs?\n",
        "\n",
        "Can you completely overfit the training set (i.e. get 100% accuracy?)\n",
        "\n",
        "This code is highly non-modulable. Create functions for each specific task.\n",
        "(hint: see [this](https://github.com/pytorch/examples/blob/master/mnist/main.py))\n",
        "\n",
        "Your training went well. Good. Why not save the weights of the network (`net.state_dict()`) using `torch.save()`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E21cHGi1N0Q",
        "outputId": "a4fa5a6b-933c-4739-8c50-6f2605e8ed6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 56.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Train loss 0.0347, Train accuracy 17.76%\n",
            "Train loss 0.0296, Train accuracy 32.55%\n",
            "Train loss 0.0282, Train accuracy 36.53%\n",
            "Train loss 0.0275, Train accuracy 38.36%\n",
            "Train loss 0.0267, Train accuracy 39.88%\n",
            "Train loss 0.0264, Train accuracy 40.66%\n",
            "Train loss 0.0261, Train accuracy 41.36%\n",
            "Train loss 0.0258, Train accuracy 41.90%\n",
            "Epoch 1\n",
            "Train loss 0.0229, Train accuracy 48.58%\n",
            "Train loss 0.0229, Train accuracy 48.80%\n",
            "Train loss 0.0229, Train accuracy 48.96%\n",
            "Train loss 0.0228, Train accuracy 49.18%\n",
            "Train loss 0.0226, Train accuracy 49.52%\n",
            "Train loss 0.0225, Train accuracy 49.65%\n",
            "Train loss 0.0224, Train accuracy 49.79%\n",
            "Train loss 0.0224, Train accuracy 49.94%\n",
            "Epoch 2\n",
            "Train loss 0.0209, Train accuracy 53.12%\n",
            "Train loss 0.0212, Train accuracy 53.03%\n",
            "Train loss 0.0212, Train accuracy 52.98%\n",
            "Train loss 0.0211, Train accuracy 53.46%\n",
            "Train loss 0.0209, Train accuracy 53.69%\n",
            "Train loss 0.0208, Train accuracy 53.82%\n",
            "Train loss 0.0208, Train accuracy 53.84%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as t\n",
        "\n",
        "# define network structure\n",
        "net = nn.Sequential(nn.Linear(3 * 32 * 32, 1000), nn.ReLU(), nn.Linear(1000, 10))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr = 0.01, momentum=0.9)\n",
        "\n",
        "# load data\n",
        "to_tensor =  t.ToTensor()\n",
        "normalize = t.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "flatten =  t.Lambda(lambda x:x.view(-1))\n",
        "\n",
        "transform_list = t.Compose([to_tensor, normalize, flatten])\n",
        "train_set = torchvision.datasets.CIFAR10(root='.', train=True, transform=transform_list, download=True)\n",
        "test_set = torchvision.datasets.CIFAR10(root='.', train=False, transform=transform_list, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64)\n",
        "\n",
        "# === Train === ###\n",
        "net.train()\n",
        "\n",
        "# train loop\n",
        "for epoch in range(3):\n",
        "    train_correct = 0\n",
        "    train_loss = 0\n",
        "    print('Epoch {}'.format(epoch))\n",
        "\n",
        "    # loop per epoch\n",
        "    for i, (batch, targets) in enumerate(train_loader):\n",
        "\n",
        "        output = net(batch)\n",
        "        loss = criterion(output, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        train_correct += pred.eq(targets.view_as(pred)).sum().item()\n",
        "        train_loss += loss\n",
        "\n",
        "        if i % 100 == 10: print('Train loss {:.4f}, Train accuracy {:.2f}%'.format(\n",
        "            train_loss / ((i+1) * 64), 100 * train_correct / ((i+1) * 64)))\n",
        "\n",
        "print('End of training.\\n')\n",
        "\n",
        "# === Test === ###\n",
        "test_correct = 0\n",
        "net.eval()\n",
        "\n",
        "# loop, over whole test set\n",
        "for i, (batch, targets) in enumerate(test_loader):\n",
        "\n",
        "    output = net(batch)\n",
        "    pred = output.max(1, keepdim=True)[1]\n",
        "    test_correct += pred.eq(targets.view_as(pred)).sum().item()\n",
        "\n",
        "print('End of testing. Test accuracy {:.2f}%'.format(\n",
        "    100 * test_correct / (len(test_loader) * 64)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7gWaywr1N0R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S07PUXwV1N0S"
      },
      "source": [
        "## Autograd tips and tricks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjQ-eU3V1N0T"
      },
      "source": [
        "Pointers are everywhere!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKwomwx21N0T"
      },
      "outputs": [],
      "source": [
        "net = nn.Linear(2, 2)\n",
        "w = net.weight\n",
        "print(w)\n",
        "\n",
        "x = torch.rand(1, 2)\n",
        "y = net(x).sum()\n",
        "y.backward()\n",
        "net.weight.data -= 0.01 * net.weight.grad # <--- What is this?\n",
        "print(w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caLysKHs1N0U"
      },
      "outputs": [],
      "source": [
        "net = nn.Linear(2, 2)\n",
        "w = net.weight.clone()\n",
        "print(w)\n",
        "\n",
        "x = torch.rand(1, 2)\n",
        "y = net(x).sum()\n",
        "y.backward()\n",
        "net.weight.data -= 0.01 * net.weight.grad # <--- What is this?\n",
        "print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae_mbo6O1N0V"
      },
      "source": [
        "Sharing weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz8QkVdS1N0V"
      },
      "outputs": [],
      "source": [
        "net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
        "net[0].weight = net[1].weight  # weight sharing\n",
        "\n",
        "x = torch.rand(1, 2)\n",
        "y = net(x).sum()\n",
        "y.backward()\n",
        "print(net[0].weight.grad)\n",
        "print(net[1].weight.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h-esqEW1N0W"
      },
      "source": [
        "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOMN9nAP1N0W"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}